{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc1a2a9-3da2-4638-8a86-9f54f51d5589",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d6ede-f6c6-43ac-aba5-7c974458d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd2475-b021-4b5c-95c9-10d231ff2494",
   "metadata": {},
   "source": [
    "### Loading the JSONs for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ab149-de2a-40b8-8552-df7a5c8225fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clip_1k_test.json\", \"r\") as f:\n",
    "    clip_results = json.load(f)\n",
    "    \n",
    "with open(\"clip_retrievals_for_lxmert.json\", \"r\") as f:\n",
    "    clip_retrievals = json.load(f)\n",
    "    \n",
    "with open(\"lxmert_1k_test.json\", \"r\") as f:\n",
    "    lxmert_results = json.load(f)\n",
    "    \n",
    "with open(\"lxmert_retrievals_for_clip.json\", \"r\") as f:\n",
    "    lxmert_retrievals = json.load(f)\n",
    "    \n",
    "with open(\"comparison.json\", \"r\") as f:\n",
    "    compare = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1115a40-806d-48d5-9025-28358fd6564c",
   "metadata": {},
   "source": [
    "### Get the image keys to properly display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0912df1-dcb2-4fae-9ed1-5f7de0725d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(os.environ['WORK_BASE']) / \"datasets/coco_ir/test/test_img_keys_1k.tsv\", \"r\") as f:\n",
    "    test_img_keys = f.readlines()\n",
    "    \n",
    "test_img_keys = [k.strip() for k in test_img_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6d60a-a9cc-4523-9c91-49d78356871b",
   "metadata": {},
   "source": [
    "### Opening the `.h5` file with all of the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026f48a-1b3d-4822-aee9-d054411e62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = h5py.File(Path(os.environ['WORK_BASE']) / \"datasets/coco_ir/test/test_imgs.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f7fed-7b49-405f-931e-0ecaf4fe23f7",
   "metadata": {},
   "source": [
    "### Converting the image indices to image IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a280ef-f135-4893-b540-2bb8e80039e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_i2t_hard = clip_results['i2t']['hard']\n",
    "for query in clip_i2t_hard:\n",
    "    query['query_key'] = test_img_keys[query['query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064594d-d99d-4445-a474-f2ef363bed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lxmert_i2t_hard = lxmert_results['i2t']['hard']\n",
    "for query in lxmert_i2t_hard:\n",
    "    query['query_key'] = test_img_keys[query['query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec43acb-5856-4a32-a446-9506891235d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_t2i_hard = clip_results['t2i']['hard']\n",
    "for query in clip_t2i_hard:\n",
    "    query['ground_truth'] = test_img_keys[query.pop('ground_truth')]\n",
    "    query['retrieved'] = list(map(lambda x: test_img_keys[x], query.pop('retrieved')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa537464-1087-4257-b205-8a4e4c782283",
   "metadata": {},
   "outputs": [],
   "source": [
    "lxmert_t2i_hard = lxmert_results['t2i']['hard']\n",
    "for query in lxmert_t2i_hard:\n",
    "    query['ground_truth'] = test_img_keys[query.pop('ground_truth')]\n",
    "    query['retrieved'] = list(map(lambda x: test_img_keys[x], query.pop('retrieved')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3fc3f-7fa5-4400-a5bd-ff36fad6274f",
   "metadata": {},
   "source": [
    "## \"Hard\" Image-Based Text Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a81ede-3305-4ba9-949b-a45b8e866ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 70)\n",
    "print('CLIP Image -> Text (HARD)')\n",
    "print('*' * 70)\n",
    "\n",
    "for hard_query in clip_i2t_hard:\n",
    "    img_query = test_imgs[hard_query['query_key']][()].astype(int)\n",
    "    plt.imshow(img_query)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    pprint(hard_query['ground_truth'])\n",
    "    pprint(hard_query['retrieved'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252cba69-d647-440b-972c-6a4fa64bf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 70)\n",
    "print('LXMERT Image -> Text (HARD)')\n",
    "print('*' * 70)\n",
    "\n",
    "for hard_query in lxmert_i2t_hard:\n",
    "    img_query = test_imgs[hard_query['query_key']][()].astype(int)\n",
    "    plt.imshow(img_query)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    pprint(hard_query['ground_truth'])\n",
    "    pprint(hard_query['retrieved'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99670cc6-3916-4bf4-8857-b82d77b23b50",
   "metadata": {},
   "source": [
    "## \"Hard\" Image-Based Text Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af62aeb-afef-401b-b163-791781b02c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 70)\n",
    "print('CLIP Text -> Image (HARD)')\n",
    "print('*' * 70)\n",
    "\n",
    "# Displays the hard textual queries for image retrieval for CLIP\n",
    "for hard_query in clip_t2i_hard:\n",
    "    cap_query = hard_query['query']\n",
    "    print(cap_query)\n",
    "    img_ground_truth = test_imgs[hard_query['ground_truth']][()].astype(int)\n",
    "    plt.imshow(img_ground_truth)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    grid = ImageGrid(fig, 111, \n",
    "                     nrows_ncols=(2, 5),  # creates 2x5 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes\n",
    "                     )\n",
    "    \n",
    "    for ax, im in zip(grid, hard_query['retrieved']):\n",
    "        img = test_imgs[im][()].astype(int)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266401c3-6b96-4a09-82b8-12c959cb680b",
   "metadata": {},
   "source": [
    "For the examples in the paper, we analyzed both retrieval results for each \"hard\" query. Whereas with text retrieval the results were able to be interpreted immediately (since the retrievals were already converted to the captions), we need to actually plot the im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65f848-50c3-4ae2-994a-75d5e58908e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 70)\n",
    "print('LXMERT retrieval for CLIP Text -> Image (HARD)')\n",
    "print('*' * 70)\n",
    "\n",
    "# Displays the hard textual queries for image retrieval for LXMERT\n",
    "for hard_query in lxmert_retrievals[\"t2i\"]:\n",
    "    cap_query = hard_query['query']\n",
    "    print(cap_query)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    grid = ImageGrid(fig, 111, \n",
    "                     nrows_ncols=(2, 5),  # creates 2x5 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes\n",
    "                     )\n",
    "    \n",
    "    for ax, im in zip(grid, hard_query['retrieved']):\n",
    "        img = test_imgs[im][()].astype(int)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde8237-6fe6-4a29-922b-3e2606280ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 70)\n",
    "print('LXMERT Text -> Image (HARD)')\n",
    "print('*' * 70)\n",
    "\n",
    "for hard_query in lxmert_t2i_hard:\n",
    "    cap_query = hard_query['query']\n",
    "    print(cap_query)\n",
    "    img_ground_truth = test_imgs[hard_query['ground_truth']][()].astype(int)\n",
    "    plt.imshow(img_ground_truth)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    grid = ImageGrid(fig, 111, \n",
    "                     nrows_ncols=(2, 5),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes\n",
    "                     )\n",
    "    \n",
    "    for ax, im in zip(grid, hard_query['retrieved']):\n",
    "        img = test_imgs[im][()].astype(int)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d459d12-99b8-47df-ae3a-612e33960143",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 70)\n",
    "print('CLIP retrieval for LXMERT Text -> Image (HARD)')\n",
    "print('*' * 70)\n",
    "\n",
    "for hard_query in clip_retrievals[\"t2i\"]:\n",
    "    cap_query = hard_query['query']\n",
    "    print(cap_query)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    grid = ImageGrid(fig, 111, \n",
    "                     nrows_ncols=(2, 5),  # creates 2x5 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes\n",
    "                     )\n",
    "    \n",
    "    for ax, im in zip(grid, hard_query['retrieved']):\n",
    "        img = test_imgs[im][()].astype(int)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152ff2b-6604-4709-b5b0-a60e9c15bea7",
   "metadata": {},
   "source": [
    "## When does CLIP perform better than the fine-tuned LXMERT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c284d4-3ddb-4524-aa67-79043142577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for better_caption in compare[\"i2t\"]:\n",
    "    img = test_imgs[better_caption[\"query\"]][()].astype(int)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f\"CLIP: [{better_caption['clip']}], LXMERT: [{better_caption['lxmert']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf178b20-ff7e-4372-9fac-ec37b2895699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for better_image in compare[\"t2i\"]:\n",
    "    print(better_image['query'])\n",
    "    print(f\"CLIP: [{better_image['clip']}], LXMERT: [{better_image['lxmert']}]\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
